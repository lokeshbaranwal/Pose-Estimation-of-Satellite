{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of SpeedvL.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lokeshbaranwal/Pose-Estimation-of-Satellite/blob/master/Final_of_SpeedvL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KGc77qXZdvp",
        "colab_type": "code",
        "outputId": "916a1b65-5d89-4405-bebe-4b392281e7f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXvaq5cyeZbQ",
        "colab_type": "code",
        "outputId": "ef993919-e4e3-4b26-9aef-0b1ff441473a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "dataset_root=\"/content/gdrive/My Drive/speed\"\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense,Flatten,Activation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from numpy import linalg as LA\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQTpWUJ8fkim",
        "colab_type": "code",
        "outputId": "889b83ea-49f5-48f3-a660-4c10857bd37c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "with open(os.path.join(dataset_root,'train.json'),'r') as train:\n",
        "  train_json=json.load(train)\n",
        "train_json[0]['q_vbs2tango']\n",
        "#len(train_json)\n",
        "#train_json\n",
        "# q=train_json[i]['q_vbs2tango']\n",
        "# r=train_json[i]['r_Vo2To_vbs_true']\n",
        "# a=q.extend(r)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.419541, -0.484436, -0.214179, 0.73718]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y12IBNK5jVlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgname_list=[]\n",
        "for i in range(len(train_json)):\n",
        "  imgname_list.append(train_json[i]['filename'])\n",
        "\n",
        "#imgname_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLbgD2bUlzzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_list=[]\n",
        "q1,q2,q3,q4,r1,r2,r3=[],[],[],[],[],[],[]\n",
        "for i in range(len(train_json)):\n",
        "  q1.append(train_json[i]['q_vbs2tango'][0])\n",
        "  q2.append(train_json[i]['q_vbs2tango'][1])\n",
        "  q3.append(train_json[i]['q_vbs2tango'][2])\n",
        "  q4.append(train_json[i]['q_vbs2tango'][3])\n",
        "  r1.append(train_json[i]['r_Vo2To_vbs_true'][0])\n",
        "  r2.append(train_json[i]['r_Vo2To_vbs_true'][1])\n",
        "  r3.append(train_json[i]['r_Vo2To_vbs_true'][2])\n",
        "  #q.extend(r)\n",
        "  #label_list.append(q)\n",
        "#label_list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Sfy7lfwlMxp",
        "colab_type": "code",
        "outputId": "6d57258a-9147-4212-b91b-fdab449775d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "col_dict={'image_names':imgname_list,'q1':q1,'q2':q2,'q3':q3,'q4':q4,'r1':r1,'r2':r2,'r3':r3}\n",
        "df=pd.DataFrame(col_dict)\n",
        "#df['labels']=label_list\n",
        "df_train,df_test=train_test_split(df,test_size=0.2)\n",
        "len(df_test)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcFFc9ZwsKjT",
        "colab_type": "code",
        "outputId": "ad472f1d-a061-4074-a03c-29abd5b2f9f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "path=\"/content/gdrive/My Drive/speed/images/train\"\n",
        "cols=['q1','q2','q3','q4','r1','r2','r3']\n",
        "datagen=ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "train_generator=datagen.flow_from_dataframe(df_train,directory=path,x_col='image_names',y_col=cols,class_mode='other',target_size=(224,224),batch_size=32,color_mode='rgb')\n",
        "validation_generator=datagen.flow_from_dataframe(df_test,directory=path,x_col='image_names',y_col=cols,class_mode='other',target_size=(224,224),batch_size=32,color_mode='rgb')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 2 invalid image filename(s) in x_col=\"image_names\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 9598 validated image filenames.\n",
            "Found 2400 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1corPUq8Aq8G",
        "colab_type": "code",
        "outputId": "e5e5f986-a3e5-47af-db53-27ced047376d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "#Building our model using Transfer Learning\n",
        "tensorflow.keras.backend.set_learning_phase(0)\n",
        "model_pretrained=ResNet50(weights='imagenet',input_shape=(224,224,3),include_top=False)\n",
        "tensorflow.keras.backend.set_learning_phase(1)\n",
        "x=model_pretrained.output\n",
        "#x=Flatten()(x)\n",
        "x=Dense(1024,activation='relu')(x)\n",
        "#x=BatchNormalization()(x)\n",
        "#x=Activation('relu')(x)\n",
        "#x=Dropout(0.5)(x)\n",
        "x=Flatten()(x)\n",
        "x=Dense(7,activation='linear')(x)\n",
        "\n",
        "model=Model(inputs=model_pretrained.input,outputs=x)\n",
        "\n",
        "# model.fit_generator(train_generator,steps_per_epoch=step_size_train,validation_data=validation_generator,validation_steps=step_size_valid,epochs=20)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0724 08:58:26.741381 139984114698112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0724 08:58:26.743218 139984114698112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0724 08:58:26.760863 139984114698112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "W0724 08:58:26.811087 139984114698112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0724 08:58:26.812530 139984114698112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0724 08:58:30.064564 139984114698112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0724 08:58:30.160864 139984114698112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeUjD6qEr9wm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i,j in enumerate(model.layers):\n",
        "#   print(i,':',j)\n",
        "# for layer in model.layers[:175]:\n",
        "#   layer.trainable=False\n",
        "# for layer in model.layers[175:]:\n",
        "#   layer.trainable=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOnecUjTQuCG",
        "colab_type": "code",
        "outputId": "6a9a6282-e4ae-4a24-d2b2-83566f0cbee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 7, 7, 1024)   2098176     activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 50176)        0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 7)            351239      flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 26,037,127\n",
            "Trainable params: 25,984,007\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miWpU1_GsFlE",
        "colab_type": "code",
        "outputId": "e4598b10-cb7c-43c3-fdb8-9d39fe738978",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "model.compile(optimizer='adam',loss='mean_squared_error') #,metrics=['mse']\n",
        "\n",
        "step_size_train=train_generator.n//train_generator.batch_size #It should typically be equal to the number of samples of your dataset divided by the batch size.\n",
        "step_size_valid=validation_generator.n//validation_generator.batch_size"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0724 08:58:41.038415 139984114698112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxw94xaJKoKY",
        "colab_type": "code",
        "outputId": "c450c863-ee38-4115-cf99-c5e00d5154f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(train_generator,steps_per_epoch=step_size_train,validation_data=validation_generator,validation_steps=step_size_valid,epochs=100)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "299/299 [==============================] - 4189s 14s/step - loss: 6.1544 - val_loss: 4.3176\n",
            "Epoch 2/100\n",
            "299/299 [==============================] - 350s 1s/step - loss: 1.2020 - val_loss: 1.5311\n",
            "Epoch 3/100\n",
            "299/299 [==============================] - 340s 1s/step - loss: 0.8419 - val_loss: 0.9665\n",
            "Epoch 4/100\n",
            "299/299 [==============================] - 337s 1s/step - loss: 0.6200 - val_loss: 0.8741\n",
            "Epoch 5/100\n",
            "299/299 [==============================] - 329s 1s/step - loss: 0.5711 - val_loss: 1.5926\n",
            "Epoch 6/100\n",
            "299/299 [==============================] - 341s 1s/step - loss: 0.4279 - val_loss: 1.0825\n",
            "Epoch 7/100\n",
            "299/299 [==============================] - 343s 1s/step - loss: 0.4289 - val_loss: 1.2178\n",
            "Epoch 8/100\n",
            "299/299 [==============================] - 342s 1s/step - loss: 0.4184 - val_loss: 0.9343\n",
            "Epoch 9/100\n",
            "299/299 [==============================] - 343s 1s/step - loss: 0.3929 - val_loss: 0.9904\n",
            "Epoch 10/100\n",
            "299/299 [==============================] - 344s 1s/step - loss: 0.3224 - val_loss: 0.7298\n",
            "Epoch 11/100\n",
            "299/299 [==============================] - 344s 1s/step - loss: 0.3012 - val_loss: 1.0024\n",
            "Epoch 12/100\n",
            "299/299 [==============================] - 338s 1s/step - loss: 0.9565 - val_loss: 10.4033\n",
            "Epoch 13/100\n",
            "299/299 [==============================] - 336s 1s/step - loss: 0.5870 - val_loss: 6.5452\n",
            "Epoch 14/100\n",
            "299/299 [==============================] - 343s 1s/step - loss: 0.5186 - val_loss: 0.7873\n",
            "Epoch 15/100\n",
            "299/299 [==============================] - 349s 1s/step - loss: 0.3899 - val_loss: 5.3743\n",
            "Epoch 16/100\n",
            "299/299 [==============================] - 340s 1s/step - loss: 0.3016 - val_loss: 0.5803\n",
            "Epoch 17/100\n",
            "299/299 [==============================] - 336s 1s/step - loss: 0.2574 - val_loss: 0.5041\n",
            "Epoch 18/100\n",
            "299/299 [==============================] - 335s 1s/step - loss: 0.2300 - val_loss: 0.5032\n",
            "Epoch 19/100\n",
            "299/299 [==============================] - 330s 1s/step - loss: 0.2246 - val_loss: 0.4410\n",
            "Epoch 20/100\n",
            "299/299 [==============================] - 327s 1s/step - loss: 0.2391 - val_loss: 1.2488\n",
            "Epoch 21/100\n",
            "299/299 [==============================] - 324s 1s/step - loss: 0.2224 - val_loss: 0.4681\n",
            "Epoch 22/100\n",
            "299/299 [==============================] - 338s 1s/step - loss: 0.2304 - val_loss: 0.5936\n",
            "Epoch 23/100\n",
            "299/299 [==============================] - 337s 1s/step - loss: 0.5825 - val_loss: 5.3221\n",
            "Epoch 24/100\n",
            "299/299 [==============================] - 341s 1s/step - loss: 0.8060 - val_loss: 1.4802\n",
            "Epoch 25/100\n",
            "299/299 [==============================] - 343s 1s/step - loss: 0.4645 - val_loss: 0.8096\n",
            "Epoch 26/100\n",
            "299/299 [==============================] - 342s 1s/step - loss: 0.3686 - val_loss: 0.7278\n",
            "Epoch 27/100\n",
            "299/299 [==============================] - 343s 1s/step - loss: 0.2526 - val_loss: 0.4600\n",
            "Epoch 28/100\n",
            "299/299 [==============================] - 345s 1s/step - loss: 0.2116 - val_loss: 0.5654\n",
            "Epoch 29/100\n",
            "299/299 [==============================] - 353s 1s/step - loss: 0.1958 - val_loss: 0.5130\n",
            "Epoch 30/100\n",
            "299/299 [==============================] - 354s 1s/step - loss: 0.1896 - val_loss: 0.4738\n",
            "Epoch 31/100\n",
            "299/299 [==============================] - 352s 1s/step - loss: 0.1767 - val_loss: 0.4606\n",
            "Epoch 32/100\n",
            "299/299 [==============================] - 350s 1s/step - loss: 0.1910 - val_loss: 0.7777\n",
            "Epoch 33/100\n",
            "299/299 [==============================] - 352s 1s/step - loss: 0.1976 - val_loss: 0.5092\n",
            "Epoch 34/100\n",
            "299/299 [==============================] - 348s 1s/step - loss: 0.2024 - val_loss: 6.7658\n",
            "Epoch 35/100\n",
            "299/299 [==============================] - 350s 1s/step - loss: 0.1955 - val_loss: 0.4947\n",
            "Epoch 36/100\n",
            "299/299 [==============================] - 349s 1s/step - loss: 0.2113 - val_loss: 12.3017\n",
            "Epoch 37/100\n",
            "299/299 [==============================] - 352s 1s/step - loss: 0.7193 - val_loss: 5.1809\n",
            "Epoch 38/100\n",
            "299/299 [==============================] - 350s 1s/step - loss: 0.4778 - val_loss: 0.7254\n",
            "Epoch 39/100\n",
            "299/299 [==============================] - 344s 1s/step - loss: 0.2626 - val_loss: 4.5634\n",
            "Epoch 40/100\n",
            "299/299 [==============================] - 341s 1s/step - loss: 0.1950 - val_loss: 0.4358\n",
            "Epoch 41/100\n",
            "299/299 [==============================] - 343s 1s/step - loss: 0.1611 - val_loss: 0.4097\n",
            "Epoch 42/100\n",
            "299/299 [==============================] - 340s 1s/step - loss: 0.1427 - val_loss: 0.4154\n",
            "Epoch 43/100\n",
            "299/299 [==============================] - 341s 1s/step - loss: 0.1323 - val_loss: 0.4569\n",
            "Epoch 44/100\n",
            "299/299 [==============================] - 361s 1s/step - loss: 0.1278 - val_loss: 0.4627\n",
            "Epoch 45/100\n",
            "299/299 [==============================] - 363s 1s/step - loss: 0.1333 - val_loss: 0.5475\n",
            "Epoch 46/100\n",
            "299/299 [==============================] - 359s 1s/step - loss: 0.1316 - val_loss: 0.4498\n",
            "Epoch 47/100\n",
            "299/299 [==============================] - 360s 1s/step - loss: 0.1121 - val_loss: 1.6468\n",
            "Epoch 48/100\n",
            "299/299 [==============================] - 362s 1s/step - loss: 0.1320 - val_loss: 0.4263\n",
            "Epoch 49/100\n",
            "299/299 [==============================] - 361s 1s/step - loss: 0.1417 - val_loss: 0.4674\n",
            "Epoch 50/100\n",
            "299/299 [==============================] - 359s 1s/step - loss: 0.1285 - val_loss: 0.5147\n",
            "Epoch 51/100\n",
            "299/299 [==============================] - 359s 1s/step - loss: 0.1312 - val_loss: 0.5101\n",
            "Epoch 52/100\n",
            "299/299 [==============================] - 359s 1s/step - loss: 0.1127 - val_loss: 0.4486\n",
            "Epoch 53/100\n",
            "299/299 [==============================] - 361s 1s/step - loss: 0.1038 - val_loss: 0.4460\n",
            "Epoch 54/100\n",
            "299/299 [==============================] - 361s 1s/step - loss: 0.1076 - val_loss: 7.1960\n",
            "Epoch 55/100\n",
            "299/299 [==============================] - 364s 1s/step - loss: 0.0978 - val_loss: 0.5608\n",
            "Epoch 56/100\n",
            "299/299 [==============================] - 364s 1s/step - loss: 0.0932 - val_loss: 0.4974\n",
            "Epoch 57/100\n",
            "299/299 [==============================] - 363s 1s/step - loss: 0.3772 - val_loss: 5.0757\n",
            "Epoch 58/100\n",
            "299/299 [==============================] - 360s 1s/step - loss: 0.5150 - val_loss: 0.6249\n",
            "Epoch 59/100\n",
            "299/299 [==============================] - 362s 1s/step - loss: 0.1942 - val_loss: 0.4908\n",
            "Epoch 60/100\n",
            "299/299 [==============================] - 362s 1s/step - loss: 0.1173 - val_loss: 0.4417\n",
            "Epoch 61/100\n",
            "299/299 [==============================] - 363s 1s/step - loss: 0.0807 - val_loss: 0.4526\n",
            "Epoch 62/100\n",
            "299/299 [==============================] - 362s 1s/step - loss: 0.0686 - val_loss: 0.4349\n",
            "Epoch 63/100\n",
            "299/299 [==============================] - 362s 1s/step - loss: 0.0582 - val_loss: 0.4392\n",
            "Epoch 64/100\n",
            "299/299 [==============================] - 363s 1s/step - loss: 0.0579 - val_loss: 0.4588\n",
            "Epoch 65/100\n",
            "299/299 [==============================] - 362s 1s/step - loss: 0.0543 - val_loss: 0.4376\n",
            "Epoch 66/100\n",
            "299/299 [==============================] - 361s 1s/step - loss: 0.0571 - val_loss: 0.4343\n",
            "Epoch 67/100\n",
            "299/299 [==============================] - 363s 1s/step - loss: 0.0637 - val_loss: 4.3271\n",
            "Epoch 68/100\n",
            "299/299 [==============================] - 362s 1s/step - loss: 0.0611 - val_loss: 0.4914\n",
            "Epoch 69/100\n",
            "299/299 [==============================] - 365s 1s/step - loss: 0.0656 - val_loss: 0.4441\n",
            "Epoch 70/100\n",
            "299/299 [==============================] - 364s 1s/step - loss: 0.0684 - val_loss: 0.6041\n",
            "Epoch 71/100\n",
            "299/299 [==============================] - 364s 1s/step - loss: 0.0606 - val_loss: 0.4450\n",
            "Epoch 72/100\n",
            "299/299 [==============================] - 363s 1s/step - loss: 0.0605 - val_loss: 0.4322\n",
            "Epoch 73/100\n",
            "299/299 [==============================] - 364s 1s/step - loss: 0.0656 - val_loss: 0.4918\n",
            "Epoch 74/100\n",
            "299/299 [==============================] - 362s 1s/step - loss: 0.0736 - val_loss: 0.4603\n",
            "Epoch 75/100\n",
            "299/299 [==============================] - 363s 1s/step - loss: 0.0672 - val_loss: 0.4771\n",
            "Epoch 76/100\n",
            "299/299 [==============================] - 365s 1s/step - loss: 0.0576 - val_loss: 0.5602\n",
            "Epoch 77/100\n",
            "299/299 [==============================] - 362s 1s/step - loss: 0.0507 - val_loss: 0.5285\n",
            "Epoch 78/100\n",
            "299/299 [==============================] - 363s 1s/step - loss: 0.0494 - val_loss: 0.5212\n",
            "Epoch 79/100\n",
            "299/299 [==============================] - 364s 1s/step - loss: 0.0572 - val_loss: 0.4562\n",
            "Epoch 80/100\n",
            "299/299 [==============================] - 366s 1s/step - loss: 0.0577 - val_loss: 0.6748\n",
            "Epoch 81/100\n",
            "299/299 [==============================] - 365s 1s/step - loss: 0.0560 - val_loss: 0.4671\n",
            "Epoch 82/100\n",
            "299/299 [==============================] - 367s 1s/step - loss: 0.0594 - val_loss: 0.5203\n",
            "Epoch 83/100\n",
            "299/299 [==============================] - 368s 1s/step - loss: 0.0553 - val_loss: 0.4463\n",
            "Epoch 84/100\n",
            "299/299 [==============================] - 366s 1s/step - loss: 0.0471 - val_loss: 0.4473\n",
            "Epoch 85/100\n",
            "299/299 [==============================] - 365s 1s/step - loss: 0.0433 - val_loss: 0.4468\n",
            "Epoch 86/100\n",
            "299/299 [==============================] - 365s 1s/step - loss: 0.0416 - val_loss: 0.4373\n",
            "Epoch 87/100\n",
            "299/299 [==============================] - 367s 1s/step - loss: 0.0402 - val_loss: 0.4242\n",
            "Epoch 88/100\n",
            "299/299 [==============================] - 366s 1s/step - loss: 0.0454 - val_loss: 0.5759\n",
            "Epoch 89/100\n",
            "299/299 [==============================] - 366s 1s/step - loss: 0.0434 - val_loss: 0.4593\n",
            "Epoch 90/100\n",
            "299/299 [==============================] - 364s 1s/step - loss: 0.0529 - val_loss: 0.5325\n",
            "Epoch 91/100\n",
            "299/299 [==============================] - 363s 1s/step - loss: 0.0544 - val_loss: 0.5228\n",
            "Epoch 92/100\n",
            "299/299 [==============================] - 366s 1s/step - loss: 0.0456 - val_loss: 0.4382\n",
            "Epoch 93/100\n",
            "299/299 [==============================] - 366s 1s/step - loss: 0.0391 - val_loss: 0.4106\n",
            "Epoch 94/100\n",
            "299/299 [==============================] - 364s 1s/step - loss: 0.0404 - val_loss: 0.6198\n",
            "Epoch 95/100\n",
            "299/299 [==============================] - 363s 1s/step - loss: 0.0390 - val_loss: 0.4513\n",
            "Epoch 96/100\n",
            "299/299 [==============================] - 363s 1s/step - loss: 0.0369 - val_loss: 0.4233\n",
            "Epoch 97/100\n",
            "299/299 [==============================] - 364s 1s/step - loss: 0.0389 - val_loss: 0.4370\n",
            "Epoch 98/100\n",
            "299/299 [==============================] - 363s 1s/step - loss: 0.0379 - val_loss: 0.4507\n",
            "Epoch 99/100\n",
            "299/299 [==============================] - 365s 1s/step - loss: 0.0389 - val_loss: 0.4223\n",
            "Epoch 100/100\n",
            "299/299 [==============================] - 366s 1s/step - loss: 0.0415 - val_loss: 0.4529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdGeMU2ZdZLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# label_list=[]\n",
        "# q1,q2,q3,q4,r1,r2,r3=[],[],[],[],[],[],[]\n",
        "# for i in range(len(real_json)):\n",
        "#   q1.append(real_json[i]['q_vbs2tango'][0])\n",
        "#   q2.append(real_json[i]['q_vbs2tango'][1])\n",
        "#   q3.append(real_json[i]['q_vbs2tango'][2])\n",
        "#   q4.append(real_json[i]['q_vbs2tango'][3])\n",
        "#   r1.append(real_json[i]['r_Vo2To_vbs_true'][0])\n",
        "#   r2.append(real_json[i]['r_Vo2To_vbs_true'][1])\n",
        "#   r3.append(real_json[i]['r_Vo2To_vbs_true'][2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7Q6rwVuc4iA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_datagen=ImageDataGenerator(rescale=1./255.)\n",
        "# test_generator=test_datagen.flow_from_dataframe(dataframe=testdf,directory=\"./test/\",x_col=\"id\",y_col=None,batch_size=32,seed=42,shuffle=False,class_mode=None,target_size=(32,32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDWsBd8B7N3-",
        "colab_type": "code",
        "outputId": "7f580ce3-e03a-4b5e-cc51-b00d7aae85a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq0KUOO68Zhe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "433fc920-2584-44fd-9f78-d180b555074b"
      },
      "source": [
        "# #Evaluating the model on Synthetic image\n",
        "# test_result=[]\n",
        "# with open(os.path.join(dataset_root,'test.json'),'r') as f_eval:\n",
        "#   test_list=json.load(f_eval)\n",
        "\n",
        "# for img in test_list:\n",
        "#   img_path=os.path.join(dataset_root,'images','test',img['filename'])\n",
        "#   img_arr=image.load_img(img_path,target_size=(224,224))\n",
        "#   x=image.img_to_array(img_arr)\n",
        "#   x=preprocess_input(x)\n",
        "#   x=np.expand_dims(x,axis=0)\n",
        "#   output=model.predict(x)\n",
        "#   test_result.append({'filename':img['filename'],'q':output[:4],'r':output[4:]}) \n",
        "  \n",
        "  \n",
        "#Evaluating the model\n",
        "test_result=[]\n",
        "q_est,r_est=[],[]\n",
        "with open(os.path.join(dataset_root,'real.json'),'r') as f_eval:\n",
        "  test_list=json.load(f_eval)\n",
        "\n",
        "for img in test_list:\n",
        "  img_path=os.path.join(dataset_root,'images','real',img['filename'])\n",
        "  img_arr=image.load_img(img_path,target_size=(224,224))\n",
        "  x=image.img_to_array(img_arr)\n",
        "  x=preprocess_input(x)\n",
        "  x=np.expand_dims(x,axis=0)\n",
        "  output=model.predict(x)\n",
        "  output=output.tolist()\n",
        "  test_result.append({'filename':img['filename'],'q':output[:4],'r':output[4:]})\n",
        "  q_est.append(output[0][:4])\n",
        "  r_est.append(output[0][4:])\n",
        "  print(output)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.40418392419815063, -0.22893975675106049, -0.17379428446292877, -0.04722781479358673, 0.1627606749534607, 0.03327885642647743, 5.12816047668457]]\n",
            "[[0.0549222007393837, 0.1314745992422104, -0.21536195278167725, -0.026365041732788086, -0.01674959808588028, -0.1818162053823471, 4.932540416717529]]\n",
            "[[0.2311042696237564, -0.17656497657299042, -0.3021416664123535, 0.10310329496860504, -0.1777907758951187, -0.0973181203007698, 5.672935962677002]]\n",
            "[[0.5005431771278381, 0.1224028691649437, -0.43007078766822815, -0.31525537371635437, 0.2711838185787201, -0.04407721385359764, 16.813438415527344]]\n",
            "[[0.3860761821269989, -0.3445126712322235, -0.04966200888156891, -0.0326576791703701, -0.10436492413282394, -0.3720170259475708, 5.503108501434326]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTSL-rchqaNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Evaluating the model on Synthetic image\n",
        "# img_path=os.path.join(dataset_root,'images','test','img000014.jpg')\n",
        "# img_arr=image.load_img(img_path,target_size=(224,224))\n",
        "# x=image.img_to_array(img_arr)\n",
        "# x=preprocess_input(x)\n",
        "# x=np.expand_dims(x,axis=0)\n",
        "# output=model.predict(x)\n",
        "# output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRB0Ovqvd3Cl",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7DLEGAlvYC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# img_path=os.path.join(dataset_root,'images','real','img000187real.jpg')\n",
        "# img_arr=image.load_img(img_path,target_size=(224,224))\n",
        "# x=image.img_to_array(img_arr)\n",
        "# x=preprocess_input(x)\n",
        "# x=np.expand_dims(x,axis=0)\n",
        "# output=model.predict(x)\n",
        "# output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L3bLqJ9gbcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Manual Calculation\n",
        "# #rgt for attitude ground truth value of image\n",
        "# #rest for attitude estimated value of image\n",
        "# rgt =3.3147212478\n",
        "# rest =3.9225399824\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km0nRd55gzRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# t=LA.norm([rgt-rest],2)/LA.norm([rgt],2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP5KfJwuhzSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# t #position_score for image 'img000187real.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyFnAU0sKqY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_json=[]\n",
        "q_gt,r_gt=[],[]\n",
        "with open(os.path.join(dataset_root,'real.json'),'r') as f:\n",
        "  real_json=json.load(f)\n",
        "for i in range(len(real_json)):\n",
        "  q_gt.append(real_json[i]['q_vbs2tango'])\n",
        "  r_gt.append(real_json[i]['r_Vo2To_vbs_true'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOwM2erzKvoK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6c7bd36a-8354-45b7-990c-249d5cdf1192"
      },
      "source": [
        "import math\n",
        "score_orientation=0\n",
        "bra_ket=[]\n",
        "for i in range(len(real_json)):\n",
        "  bra_ket.append(q_est[i][0]*q_gt[i][0]+q_est[i][1]*q_gt[i][1]+q_est[i][2]*q_gt[i][2]+q_est[i][3]*q_gt[i][3])\n",
        "  \n",
        "  \n",
        "for i in range(len(real_json)):\n",
        "  if bra_ket[i]<1:\n",
        "    score_orientation+=2*math.acos(bra_ket[i])\n",
        "score_orientation\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15.471092171206525"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbmG4VWFKysP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5eed7d0f-5671-4113-9a33-c31e59ec0807"
      },
      "source": [
        "from numpy import linalg\n",
        "score_position=0\n",
        "for i in range(len(real_json)):\n",
        "   score_position+=(abs(linalg.norm([r_gt[i]],2)-linalg.norm([r_est[i]],2))/linalg.norm([r_gt[i]],2))\n",
        "\n",
        "#linalg.norm([r_gt[0]])\n",
        "score_position"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.851159499970017"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHgs1AIyK29G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "99abceda-dd59-4abd-fa5b-1253ccd462ac"
      },
      "source": [
        "score=(score_orientation+score_position)/len(real_json)\n",
        "score"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.064450334235309"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}